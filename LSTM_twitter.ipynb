{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSZTsGuGfoXZPu3/yaWZUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phamquocanh149/Twitter_Sentiment_Analysis/blob/main/LSTM_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFObDsuyb8f-",
        "outputId": "a879719f-dc73-442e-83c7-375830351e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "path1 = \"/content/drive/MyDrive/Colab Notebooks/TwitterSentimentAnalysis/twitter_training.csv\"\n",
        "path2 = \"/content/drive/MyDrive/Colab Notebooks/TwitterSentimentAnalysis/twitter_validation.csv\"\n",
        "train_df = pd.read_csv(path1)\n",
        "test_df = pd.read_csv(path2)\n",
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lfuF-7ncOk3",
        "outputId": "9013a76d-a5e4-4e9f-be06-41ed10e9d292"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   2401  Borderlands  Positive  \\\n",
            "0  2401  Borderlands  Positive   \n",
            "1  2401  Borderlands  Positive   \n",
            "2  2401  Borderlands  Positive   \n",
            "3  2401  Borderlands  Positive   \n",
            "4  2401  Borderlands  Positive   \n",
            "\n",
            "  im getting on borderlands and i will murder you all ,  \n",
            "0  I am coming to the borders and I will kill you...     \n",
            "1  im getting on borderlands and i will kill you ...     \n",
            "2  im coming on borderlands and i will murder you...     \n",
            "3  im getting on borderlands 2 and i will murder ...     \n",
            "4  im getting into borderlands and i can murder y...     \n",
            "   3364   Facebook Irrelevant  \\\n",
            "0   352     Amazon    Neutral   \n",
            "1  8312  Microsoft   Negative   \n",
            "2  4371      CS-GO   Negative   \n",
            "3  4433     Google    Neutral   \n",
            "4  6273       FIFA   Negative   \n",
            "\n",
            "  I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tomâ€™s great auntie as â€˜Hayley canâ€™t get out of bedâ€™ and told to his grandma, who now thinks Iâ€™m a lazy, terrible person ðŸ¤£  \n",
            "0  BBC News - Amazon boss Jeff Bezos rejects clai...                                                                                                                                                                                                  \n",
            "1  @Microsoft Why do I pay for WORD when it funct...                                                                                                                                                                                                  \n",
            "2  CSGO matchmaking is so full of closet hacking,...                                                                                                                                                                                                  \n",
            "3  Now the President is slapping Americans in the...                                                                                                                                                                                                  \n",
            "4  Hi @EAHelp Iâ€™ve had Madeleine McCann in my cel...                                                                                                                                                                                                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns = [\"col1\", \"col2\", \"label\", \"text\"]\n",
        "test_df.columns = [\"col1\", \"col2\", \"label\", \"text\"]\n",
        "train_df = train_df.drop(columns=[\"col1\", \"col2\"])\n",
        "train_df['text'] = train_df['text'].str.lower()\n",
        "test_df['text'] = test_df['text'].str.lower()\n",
        "test_df = test_df.drop(columns=[\"col1\", \"col2\"])\n",
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp2NN94bdMzE",
        "outputId": "328a242b-ed62-4dc4-d469-6485b41b273a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                               text\n",
            "0  Positive  i am coming to the borders and i will kill you...\n",
            "1  Positive  im getting on borderlands and i will kill you ...\n",
            "2  Positive  im coming on borderlands and i will murder you...\n",
            "3  Positive  im getting on borderlands 2 and i will murder ...\n",
            "4  Positive  im getting into borderlands and i can murder y...\n",
            "      label                                               text\n",
            "0   Neutral  bbc news - amazon boss jeff bezos rejects clai...\n",
            "1  Negative  @microsoft why do i pay for word when it funct...\n",
            "2  Negative  csgo matchmaking is so full of closet hacking,...\n",
            "3   Neutral  now the president is slapping americans in the...\n",
            "4  Negative  hi @eahelp iâ€™ve had madeleine mccann in my cel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYkwi9411EIx",
        "outputId": "d5a873fc-92a5-4cac-97b9-2cab1d45b2fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(74681, 2)\n",
            "(999, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)\n",
        "print(test_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h53nDRphdVy4",
        "outputId": "77ee487c-d828-463c-b6f8-37b8d7d178cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['label', 'text'], dtype='object')\n",
            "Index(['label', 'text'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.dtypes)\n",
        "print(test_df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tDEhE5FdYh9",
        "outputId": "f97300f2-aa82-4e6c-9878-7cea7e9ec40a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label    object\n",
            "text     object\n",
            "dtype: object\n",
            "label    object\n",
            "text     object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.isnull().sum())\n",
        "print(test_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_Ulb96jda29",
        "outputId": "9dcdaa9b-7170-4c69-c68b-b1546ed0273e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label      0\n",
            "text     686\n",
            "dtype: int64\n",
            "label    0\n",
            "text     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['label'].unique())\n",
        "print(test_df['label'].unique())\n",
        "print(\"-----------------------------\")\n",
        "print(train_df['label'].value_counts())\n",
        "print(\"-----------------------------\")\n",
        "print(test_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg2LtTyzdg8m",
        "outputId": "7c66e64a-957d-4e53-f27b-27853145f10e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Positive' 'Neutral' 'Negative' 'Irrelevant']\n",
            "['Neutral' 'Negative' 'Positive' 'Irrelevant']\n",
            "-----------------------------\n",
            "label\n",
            "Negative      22542\n",
            "Positive      20831\n",
            "Neutral       18318\n",
            "Irrelevant    12990\n",
            "Name: count, dtype: int64\n",
            "-----------------------------\n",
            "label\n",
            "Neutral       285\n",
            "Positive      277\n",
            "Negative      266\n",
            "Irrelevant    171\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgSMxGrGeTSm",
        "outputId": "b5bbd33f-448c-470a-8e3f-62dfa9364cbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am coming to the borders and i will kill you all,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Drop rows with missing values in the 'text' column BEFORE encoding labels\n",
        "train_df.dropna(subset=['text'], inplace=True)\n",
        "test_df.dropna(subset=['text'], inplace=True)\n",
        "\n",
        "y_train = le.fit_transform(train_df['label'])\n",
        "y_test = le.transform(test_df['label'])"
      ],
      "metadata": {
        "id": "h34jT2rbeWvV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmbLi_pLesmd",
        "outputId": "92fa059d-478f-49f6-fa40-72cfa6edbdac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7d1b329095e0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(y_test[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De9pbTuLX8Q8",
        "outputId": "a92b6d25-8656-42fc-80c0-3dc92f920c57"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 torchtext==0.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzgwME9BfPKN",
        "outputId": "a4b2cd7f-bc39-4c05-a7bf-8c7c48272b4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torchvision==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0) (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.transforms import VocabTransform\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n"
      ],
      "metadata": {
        "id": "2_5yWaDUfVa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35ef406-ffd8-42fd-f6d5-c65e01d118b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchtext/transforms.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/functional.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "8loNS_MFglVy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_token = train_df['text'].apply(tokenizer)\n",
        "test_token = test_df['text'].apply(tokenizer)"
      ],
      "metadata": {
        "id": "PB7qAJC6glyt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_token.head())\n",
        "print(test_token.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cfg5G2Pg60r",
        "outputId": "3edd4516-5052-4447-f5cf-76c018e55732"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [i, am, coming, to, the, borders, and, i, will...\n",
            "1    [i, m, getting, on, borderlands, and, i, will,...\n",
            "2    [i, m, coming, on, borderlands, and, i, will, ...\n",
            "3    [i, m, getting, on, borderlands, 2, and, i, wi...\n",
            "4    [i, m, getting, into, borderlands, and, i, can...\n",
            "Name: text, dtype: object\n",
            "0    [bbc, news, -, amazon, boss, jeff, bezos, reje...\n",
            "1    [@microsoft, why, do, i, pay, for, word, when,...\n",
            "2    [csgo, matchmaking, is, so, full, of, closet, ...\n",
            "3    [now, the, president, is, slapping, americans,...\n",
            "4    [hi, @eahelp, i, â€™ve, had, madeleine, mccann, ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_token[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSuZWUtRg_Xc",
        "outputId": "7ba8491d-faab-4b08-e3dd-21bc06c432bf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'am', 'coming', 'to', 'the', 'borders', 'and', 'i', 'will', 'kill', 'you', 'all', ',']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "X_train = train_token.apply(lambda tokens: [token for token in tokens if token not in string.punctuation])\n",
        "X_test = test_token.apply(lambda tokens: [token for token in tokens if token not in string.punctuation])"
      ],
      "metadata": {
        "id": "ELotADZUhEOE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBlPx4d5h0iH",
        "outputId": "a85795d4-96f0-4082-e2e2-f0eb1e11cc4f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'am', 'coming', 'to', 'the', 'borders', 'and', 'i', 'will', 'kill', 'you', 'all']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator((token for token in X_train), specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "o6ZHgyxPh2JE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vT7pUjXkXLK",
        "outputId": "3b60529f-b47f-44a8-98d1-3c3267a50654"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(y_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mtbqe7XkZPr",
        "outputId": "13050ce0-28c5-48c8-9645-f6d9616f3ea7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = VocabTransform(vocab)"
      ],
      "metadata": {
        "id": "B6oKDzrwkgvG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.apply(transform)\n",
        "X_test = X_test.apply(transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4CB4c0ZkkbC",
        "outputId": "90895e39-d63f-471b-f3cc-f2409382236f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/_jit_internal.py:1358: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYZbAog1lDVq",
        "outputId": "e5ecbda0-0eea-421a-b11b-d2e7986199ed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         [3, 113, 399, 4, 2, 6654, 5, 3, 56, 428, 13, 27]\n",
            "1            [3, 118, 174, 15, 159, 5, 3, 56, 428, 13, 27]\n",
            "2           [3, 118, 399, 15, 159, 5, 3, 56, 1767, 13, 27]\n",
            "3        [3, 118, 174, 15, 159, 41, 5, 3, 56, 1767, 13,...\n",
            "4          [3, 118, 174, 189, 159, 5, 3, 47, 1767, 13, 27]\n",
            "                               ...                        \n",
            "74676    [26, 1935, 17, 2, 609, 11426, 7, 16, 2151, 8, ...\n",
            "74677    [26, 1935, 17, 16, 2151, 4569, 11426, 8, 306, ...\n",
            "74678    [26, 1935, 2, 609, 11426, 7, 16, 2151, 8, 43, ...\n",
            "74679    [26, 1935, 729, 2, 609, 11426, 7, 16, 2151, 8,...\n",
            "74680    [26, 36, 2, 609, 11426, 7, 16, 2151, 8, 36, 30...\n",
            "Name: text, Length: 73995, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length= [len(s) for s in X_train]\n",
        "MAXLEN = max(length)\n",
        "print(MAXLEN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRDEgrt9lFBS",
        "outputId": "ff3adf11-fea2-4971-c597-bab56bd1edec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counter = Counter(length)\n",
        "print(sorted(counter.items()))\n",
        "MAXLEN = 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIiNo6vzb8sC",
        "outputId": "b9f19822-06b7-4c79-8997-62823937d1aa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 51), (1, 2470), (2, 1657), (3, 2141), (4, 2285), (5, 2583), (6, 2608), (7, 2604), (8, 2472), (9, 2491), (10, 2466), (11, 2542), (12, 2552), (13, 2548), (14, 2360), (15, 2496), (16, 2304), (17, 2092), (18, 1970), (19, 1941), (20, 1599), (21, 1524), (22, 1534), (23, 1437), (24, 1356), (25, 1206), (26, 1114), (27, 1079), (28, 1108), (29, 983), (30, 982), (31, 940), (32, 836), (33, 782), (34, 762), (35, 667), (36, 697), (37, 630), (38, 579), (39, 573), (40, 567), (41, 566), (42, 592), (43, 509), (44, 569), (45, 490), (46, 531), (47, 439), (48, 475), (49, 655), (50, 423), (51, 399), (52, 372), (53, 342), (54, 279), (55, 290), (56, 235), (57, 204), (58, 193), (59, 140), (60, 135), (61, 111), (62, 82), (63, 89), (64, 54), (65, 48), (66, 39), (67, 34), (68, 17), (69, 14), (70, 19), (71, 14), (72, 6), (73, 8), (74, 3), (75, 3), (76, 5), (77, 1), (78, 2), (80, 2), (81, 1), (84, 1), (95, 1), (97, 1), (98, 1), (99, 9), (105, 1), (107, 1), (151, 1), (166, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad_index = vocab['<pad>']\n",
        "def encode_sen(encode, pad_index, max_length = MAXLEN):\n",
        "\n",
        "  if len(encode) < max_length:\n",
        "    encode += [pad_index] * (max_length - len(encode))\n",
        "  else:\n",
        "    encode = encode[:max_length]\n",
        "  return encode"
      ],
      "metadata": {
        "id": "QsSjio-SlYRL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.apply(lambda x: encode_sen(x, pad_index))\n",
        "X_test = X_test.apply(lambda x: encode_sen(x, pad_index))"
      ],
      "metadata": {
        "id": "55E4CgA8lae6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.iloc[0])\n",
        "print(type(X_train.iloc[0][0]))"
      ],
      "metadata": {
        "id": "ozAc9Yclp_L3",
        "outputId": "8a6f2552-128c-4df8-80d5-01a6d4bc0df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 113, 399, 4, 2, 6654, 5, 3, 56, 428, 13, 27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = torch.tensor(X, dtype=torch.long)\n",
        "    self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n"
      ],
      "metadata": {
        "id": "0DBnqdDcldVp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train = TextDataset(X_train, np.array(y_train, dtype=int))\n",
        "test = TextDataset(X_test, np.array(y_test, dtype=int))"
      ],
      "metadata": {
        "id": "HNQaB7PMliWD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = DataLoader(train, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "wvRjGR6ZlkTx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim,\n",
        "                                 batch_first=True)\n",
        "\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text dim: [batch size, sentence length]\n",
        "        embedded = self.embedding(text)\n",
        "        output, (hidden, cell) = self.LSTM(embedded)\n",
        "        # output dim: [sentence length, batch size, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "        hidden.squeeze_(0)\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ],
      "metadata": {
        "id": "aujGzQkRlp3T"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(14)\n",
        "model = LSTM(input_dim=len(vocab),\n",
        "            embedding_dim=128,\n",
        "            hidden_dim=128,\n",
        "            output_dim=4 # could use 1 for binary classification\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "75nrGcl6mNPO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, optimizer, criterion, device, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            acc = (predictions.argmax(1) == y_batch).sum().item() / len(y_batch)\n",
        "            epoch_acc += acc\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        avg_acc = epoch_acc / len(train_loader)\n",
        "\n",
        "        # Evaluate\n",
        "        val_loss, val_acc, val_labels, val_preds = evaluate(model, valid_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: \"\n",
        "              f\"Train Loss={avg_loss:.4f}, Train Acc={avg_acc:.4f} | \"\n",
        "              f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "        # In classification report\n",
        "        print(\"Validation Classification Report:\")\n",
        "        print(classification_report(val_labels, val_preds))"
      ],
      "metadata": {
        "id": "Dxr4HFPXmZss"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            all_preds.extend(predictions.argmax(1).cpu().numpy())\n",
        "            all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    avg_loss = epoch_loss / len(data_loader)\n",
        "    avg_acc = (np.array(all_preds) == np.array(all_labels)).mean()\n",
        "    return avg_loss, avg_acc, all_labels, all_preds"
      ],
      "metadata": {
        "id": "_CMgB1K5nozp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, test_loader, optimizer, criterion, DEVICE, epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NNXjaiZmkUH",
        "outputId": "7fd8594d-d456-4da8-e4bf-35e375ce6794"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.3686, Train Acc=0.2982 | Val Loss=1.3731, Val Acc=0.2683\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.01      0.01       171\n",
            "           1       0.27      1.00      0.42       266\n",
            "           2       1.00      0.00      0.01       285\n",
            "           3       0.00      0.00      0.00       277\n",
            "\n",
            "    accuracy                           0.27       999\n",
            "   macro avg       0.57      0.25      0.11       999\n",
            "weighted avg       0.53      0.27      0.12       999\n",
            "\n",
            "Epoch 2: Train Loss=1.1902, Train Acc=0.4650 | Val Loss=0.8182, Val Acc=0.6907\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.11      0.18       171\n",
            "           1       0.71      0.85      0.78       266\n",
            "           2       0.61      0.83      0.70       285\n",
            "           3       0.79      0.75      0.77       277\n",
            "\n",
            "    accuracy                           0.69       999\n",
            "   macro avg       0.68      0.64      0.61       999\n",
            "weighted avg       0.69      0.69      0.65       999\n",
            "\n",
            "Epoch 3: Train Loss=0.7458, Train Acc=0.7166 | Val Loss=0.4349, Val Acc=0.8589\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.68      0.76       171\n",
            "           1       0.87      0.92      0.90       266\n",
            "           2       0.81      0.89      0.85       285\n",
            "           3       0.90      0.87      0.88       277\n",
            "\n",
            "    accuracy                           0.86       999\n",
            "   macro avg       0.86      0.84      0.85       999\n",
            "weighted avg       0.86      0.86      0.86       999\n",
            "\n",
            "Epoch 4: Train Loss=0.4630, Train Acc=0.8331 | Val Loss=0.3498, Val Acc=0.8939\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.78      0.84       171\n",
            "           1       0.92      0.95      0.93       266\n",
            "           2       0.84      0.93      0.88       285\n",
            "           3       0.93      0.87      0.90       277\n",
            "\n",
            "    accuracy                           0.89       999\n",
            "   macro avg       0.90      0.88      0.89       999\n",
            "weighted avg       0.90      0.89      0.89       999\n",
            "\n",
            "Epoch 5: Train Loss=0.3307, Train Acc=0.8820 | Val Loss=0.2917, Val Acc=0.9109\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86       171\n",
            "           1       0.93      0.96      0.95       266\n",
            "           2       0.88      0.92      0.90       285\n",
            "           3       0.94      0.91      0.92       277\n",
            "\n",
            "    accuracy                           0.91       999\n",
            "   macro avg       0.91      0.90      0.91       999\n",
            "weighted avg       0.91      0.91      0.91       999\n",
            "\n",
            "Epoch 6: Train Loss=0.2571, Train Acc=0.9087 | Val Loss=0.2936, Val Acc=0.9179\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.88      0.89       171\n",
            "           1       0.95      0.95      0.95       266\n",
            "           2       0.88      0.93      0.91       285\n",
            "           3       0.93      0.89      0.91       277\n",
            "\n",
            "    accuracy                           0.92       999\n",
            "   macro avg       0.92      0.91      0.92       999\n",
            "weighted avg       0.92      0.92      0.92       999\n",
            "\n",
            "Epoch 7: Train Loss=0.2087, Train Acc=0.9243 | Val Loss=0.2768, Val Acc=0.9309\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.91       171\n",
            "           1       0.94      0.97      0.96       266\n",
            "           2       0.89      0.95      0.92       285\n",
            "           3       0.97      0.91      0.94       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.93      0.93       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n",
            "Epoch 8: Train Loss=0.1837, Train Acc=0.9334 | Val Loss=0.2828, Val Acc=0.9289\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90       171\n",
            "           1       0.94      0.95      0.94       266\n",
            "           2       0.90      0.95      0.92       285\n",
            "           3       0.96      0.91      0.94       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.93      0.93       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n",
            "Epoch 9: Train Loss=0.1726, Train Acc=0.9367 | Val Loss=0.3006, Val Acc=0.9289\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.85      0.90       171\n",
            "           1       0.93      0.98      0.95       266\n",
            "           2       0.90      0.94      0.92       285\n",
            "           3       0.95      0.91      0.93       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.92      0.93       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n",
            "Epoch 10: Train Loss=0.1597, Train Acc=0.9411 | Val Loss=0.3267, Val Acc=0.9219\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.86       171\n",
            "           1       0.95      0.96      0.96       266\n",
            "           2       0.88      0.95      0.91       285\n",
            "           3       0.95      0.91      0.93       277\n",
            "\n",
            "    accuracy                           0.92       999\n",
            "   macro avg       0.92      0.91      0.92       999\n",
            "weighted avg       0.92      0.92      0.92       999\n",
            "\n",
            "Epoch 11: Train Loss=0.1600, Train Acc=0.9414 | Val Loss=0.3418, Val Acc=0.9259\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.87       171\n",
            "           1       0.94      0.98      0.96       266\n",
            "           2       0.90      0.94      0.92       285\n",
            "           3       0.94      0.92      0.93       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.92      0.92       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n",
            "Epoch 12: Train Loss=0.1470, Train Acc=0.9453 | Val Loss=0.3392, Val Acc=0.9239\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.87      0.89       171\n",
            "           1       0.94      0.97      0.95       266\n",
            "           2       0.89      0.95      0.92       285\n",
            "           3       0.95      0.90      0.92       277\n",
            "\n",
            "    accuracy                           0.92       999\n",
            "   macro avg       0.93      0.92      0.92       999\n",
            "weighted avg       0.93      0.92      0.92       999\n",
            "\n",
            "Epoch 13: Train Loss=0.1315, Train Acc=0.9505 | Val Loss=0.3331, Val Acc=0.9289\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       171\n",
            "           1       0.96      0.97      0.96       266\n",
            "           2       0.91      0.92      0.91       285\n",
            "           3       0.95      0.92      0.94       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.93      0.93       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n",
            "Epoch 14: Train Loss=0.1383, Train Acc=0.9479 | Val Loss=0.3025, Val Acc=0.9339\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.90       171\n",
            "           1       0.96      0.97      0.96       266\n",
            "           2       0.94      0.92      0.93       285\n",
            "           3       0.94      0.94      0.94       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.93      0.93       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n",
            "Epoch 15: Train Loss=0.1367, Train Acc=0.9484 | Val Loss=0.2832, Val Acc=0.9329\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90       171\n",
            "           1       0.94      0.97      0.96       266\n",
            "           2       0.92      0.92      0.92       285\n",
            "           3       0.96      0.93      0.94       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.93      0.93       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n",
            "Epoch 16: Train Loss=0.1278, Train Acc=0.9512 | Val Loss=0.2941, Val Acc=0.9359\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       171\n",
            "           1       0.94      0.97      0.95       266\n",
            "           2       0.93      0.93      0.93       285\n",
            "           3       0.95      0.93      0.94       277\n",
            "\n",
            "    accuracy                           0.94       999\n",
            "   macro avg       0.93      0.93      0.93       999\n",
            "weighted avg       0.94      0.94      0.94       999\n",
            "\n",
            "Epoch 17: Train Loss=0.1238, Train Acc=0.9524 | Val Loss=0.3629, Val Acc=0.9379\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.87      0.91       171\n",
            "           1       0.94      0.98      0.96       266\n",
            "           2       0.92      0.94      0.93       285\n",
            "           3       0.96      0.94      0.95       277\n",
            "\n",
            "    accuracy                           0.94       999\n",
            "   macro avg       0.94      0.93      0.93       999\n",
            "weighted avg       0.94      0.94      0.94       999\n",
            "\n",
            "Epoch 18: Train Loss=0.1219, Train Acc=0.9525 | Val Loss=0.3443, Val Acc=0.9389\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.87      0.90       171\n",
            "           1       0.94      0.97      0.95       266\n",
            "           2       0.91      0.95      0.93       285\n",
            "           3       0.97      0.94      0.96       277\n",
            "\n",
            "    accuracy                           0.94       999\n",
            "   macro avg       0.94      0.93      0.94       999\n",
            "weighted avg       0.94      0.94      0.94       999\n",
            "\n",
            "Epoch 19: Train Loss=0.1189, Train Acc=0.9538 | Val Loss=0.3998, Val Acc=0.9359\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.87      0.90       171\n",
            "           1       0.95      0.97      0.96       266\n",
            "           2       0.90      0.95      0.92       285\n",
            "           3       0.97      0.93      0.95       277\n",
            "\n",
            "    accuracy                           0.94       999\n",
            "   macro avg       0.94      0.93      0.93       999\n",
            "weighted avg       0.94      0.94      0.94       999\n",
            "\n",
            "Epoch 20: Train Loss=0.1139, Train Acc=0.9561 | Val Loss=0.4254, Val Acc=0.9259\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.84      0.88       171\n",
            "           1       0.93      0.98      0.95       266\n",
            "           2       0.88      0.95      0.92       285\n",
            "           3       0.98      0.90      0.94       277\n",
            "\n",
            "    accuracy                           0.93       999\n",
            "   macro avg       0.93      0.92      0.92       999\n",
            "weighted avg       0.93      0.93      0.93       999\n",
            "\n"
          ]
        }
      ]
    }
  ]
}